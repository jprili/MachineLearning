{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fc8c50c-b49f-4ee7-8fe4-271da7a18e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mnist import MNIST\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a510c9c7-8f7f-45c4-8080-88f7e39f5b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_numspercent(num, arr):\n",
    "    print(np.count_nonzero(arr == num)/len(arr))\n",
    "    \n",
    "def printShape(name, arr):\n",
    "    print(\"{0} shape:\".format(name) + str(arr.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53f7c6ba-912a-489f-b9ce-b5e9ea853117",
   "metadata": {},
   "outputs": [],
   "source": [
    "mndata = MNIST(\"dat\")\n",
    "train = np.array(mndata.load_training()).T\n",
    "test = np.array(mndata.load_testing()).T\n",
    "\n",
    "# testLabels = test[:, 1]\n",
    "\n",
    "# for i in range(10):\n",
    "#    count_numspercent(i, testLabels)\n",
    "    \n",
    "# print(type(test[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b72aa5f-8d18-4d23-9d39-8bb7d1d27ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def smd(z):\n",
    "        \"\"\"sigmoid function\"\"\"\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "    \n",
    "    def difsmd(z):\n",
    "        return smd(z) * (1 - smd(z))\n",
    "    \n",
    "    def oneHot(y):\n",
    "        arr = np.zeros(10)\n",
    "        arr[y] = 1\n",
    "        return np.array([arr]).T\n",
    "    \n",
    "    def reLU(z):\n",
    "        return np.maximum(0, z)\n",
    "    \n",
    "    def difReLU(z):\n",
    "        if isinstance(z, np.ndarray):\n",
    "            z = np.array([i > 0 for i in z])\n",
    "            return z\n",
    "        \n",
    "        return z > 0\n",
    "    \n",
    "    def softMax(z, z_arr):\n",
    "        sum_exp_arr = sum(np.exp(z_arr))\n",
    "        \n",
    "        if isinstance(z, np.ndarray):\n",
    "            arr = np.array([np.exp(i)/sum_exp_arr for i in z])\n",
    "            return arr\n",
    "        \n",
    "        return np.exp(z)/sum(np.exp(z_arr))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a070e63-f1af-4c99-b0e8-6e0872a00cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(object):\n",
    "    def __init__(self, sizes):\n",
    "        \"\"\"\n",
    "        constructor for a neural network.\n",
    "        from https://github.com/mnielsen/neural-networks-and-deep-learning/\n",
    "             blob/master/src/network.py\n",
    "        \"\"\"\n",
    "        self.nLayers = len(sizes)\n",
    "        self.sizes = sizes\n",
    "        \n",
    "        # array of bias vectors, list with `nLayers` amount of vecs\n",
    "        # containing `size` elements\n",
    "        \n",
    "        self.biases = [np.random.randn(nextSize, 1) \\\n",
    "                       for nextSize in sizes[1:]]\n",
    "        \n",
    "        # array of weight matrices, if the previous layer is \n",
    "        # sized a, and next layer b, the weight matrix would\n",
    "        # be sized (b * a) to accomodate transformation\n",
    "        # (b * 1) = (b * a) . (a * 1)\n",
    "        \n",
    "        self.weights = [np.random.randn(nextSize, prevSize) \\\n",
    "                        for prevSize, nextSize in zip(sizes[:-1], sizes[1:])]\n",
    "        \n",
    "        self.prev_nab_W = [np.zeros(w.shape) for w in self.weights]\n",
    "        self.prev_nab_B = [np.zeros(b.shape) for b in self.biases]\n",
    "    \n",
    "    def stochasticGradDesc(self, trainDat, nEpoch, sSSize, rate, testDat = None):\n",
    "        \n",
    "        print(f\"starting SGD with batch size {sSSize}, learning rate {rate}\")\n",
    "        print(f\"up to {nEpoch} epochs\")\n",
    "        \n",
    "        if testDat is not None: \n",
    "            nTest = len(testDat)\n",
    "            percent_list = []\n",
    "        \n",
    "        nTrain = len(trainDat)\n",
    "        \n",
    "        for i in range(nEpoch):\n",
    "            random.shuffle(trainDat)\n",
    "            \n",
    "            subSets = [train[k : k + sSSize] for k in range(0, nTrain, sSSize)]\n",
    "            \n",
    "            for subSet in subSets:\n",
    "                self.updSubSet(subSet, rate)\n",
    "                \n",
    "            if testDat is not None:\n",
    "                percent = self.evaluate(testDat)/nTest\n",
    "                print(f\"epoch {i + 1}/{nEpoch}; accuracy: {percent:.1%}.\")\n",
    "                percent_list.append(percent)\n",
    "            \n",
    "            else:\n",
    "                print(f\"epoch {i + 1} complete\")\n",
    "        \n",
    "            rate = (/(i + 1)) * rate\n",
    "                \n",
    "        plt.plot(np.arange(nEpoch), percent_list, \"k--\")\n",
    "        print(\"end.\")\n",
    "        plt.show()\n",
    "        \n",
    "    def feedFwd(self, arr):\n",
    "        \"\"\"\n",
    "        forward feeding\n",
    "        \"\"\"\n",
    "        arr = np.array([arr]).T\n",
    "        # printShape(\"input_arr\", arr)\n",
    "        \n",
    "        # i = 0 \n",
    "        \n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            z = w @ arr + b\n",
    "            # printShape(\"weight {0}\".format(i), w)\n",
    "            arr = smd(z)\n",
    "            # printShape(\"output_arr {0}\".format(i), arr)\n",
    "            # i += 1\n",
    "            \n",
    "        # print(arr)\n",
    "        # print(\"end\")\n",
    "        \n",
    "        return arr\n",
    "\n",
    "    def evaluate(self, testDat):\n",
    "        results = [(np.argmax(self.feedFwd(x)), y) for (x, y) in testDat]\n",
    "        # tuple (int, int)\n",
    "        return sum(int(x == y) for x, y in results)\n",
    "        \n",
    "        \n",
    "    def updSubSet(self, subSet, rate):\n",
    "        \n",
    "        # initialise weight gradients and bias gradients\n",
    "        \n",
    "        nabB = [np.zeros(b.shape) for b in self.biases]\n",
    "        nabW = [np.zeros(w.shape) for w in self.weights]\n",
    "        \n",
    "        set_size = len(subSet)\n",
    "        batch_rate = rate/set_size\n",
    "        \n",
    "        # update\n",
    "        \n",
    "        for x, y in subSet:\n",
    "            delNabB, delNabW = self.propBwd(x, y)\n",
    "            \n",
    "            nabB = [nB + dnB for (nB, dnB) in zip(nabB, delNabB)]\n",
    "            nabW = [nW + dnW for (nW, dnW) in zip(nabW, delNabW)]\n",
    "            \n",
    "            \n",
    "        self.weights = [Wi - batch_rate * nabWi \\\n",
    "                        for Wi, nabWi in zip(self.weights, nabW)]\n",
    "        \n",
    "        self.biases = [Bi - batch_rate * nabBi \\\n",
    "                       for Bi, nabBi in zip(self.biases, nabB)]\n",
    "        \n",
    "    def difCost(self, outAct, y):\n",
    "        return outAct - y # (10 * 1)\n",
    "        \n",
    "    def propBwd(self, x, y):\n",
    "        \"\"\"\n",
    "        backwards propagation\n",
    "        \n",
    "        x - activation layer: ndarray, size m * 1\n",
    "        y - output: int, could be converted to ndarray, size 10 * 1\n",
    "            with oneHot(y).\n",
    "            \n",
    "        return:\n",
    "        \"\"\"\n",
    "        \n",
    "        # initialise weight gradients and bias gradients\n",
    "        \n",
    "        nabB = [np.zeros(b.shape) for b in self.biases]\n",
    "        nabW = [np.zeros(w.shape) for w in self.weights]\n",
    "        \n",
    "        # forward propagation\n",
    "        \n",
    "        act = np.array([x]).T\n",
    "        \n",
    "        acts = [act]\n",
    "        \n",
    "        zVecs = []\n",
    "        \n",
    "        # feedFwd is not called to store the z and a values\n",
    "        \n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            z = (w @ act) + b # (m * 1)\n",
    "            act = smd(z)\n",
    "            \n",
    "            zVecs.append(z)\n",
    "            acts.append(act)\n",
    "            \n",
    "            \n",
    "        # bwd; output (acts[-1]) to first hidden (acts[-2])\n",
    "        delta = self.difCost(acts[-1], oneHot(y))\n",
    "        \n",
    "        mo_fac = 0.5\n",
    "        \n",
    "        nabW[-1] = delta @ np.array(acts[-2]).T + (mo_fac * self.prev_nab_W[-1])\n",
    "        nabB[-1] = delta + (mo_fac * self.prev_nab_B[-1]) # (out * 1)\n",
    "        \n",
    "        # for the rest of the network\n",
    "        \n",
    "        for l in range(2, self.nLayers):\n",
    "            z = zVecs[-l]\n",
    "            \n",
    "            delta = (self.weights[-l + 1].T @ delta) * difsmd(z)\n",
    "            \n",
    "            nabW[-l] = delta @ acts[-l - 1].T + (mo_fac * self.prev_nab_W[-l]) # (m * 1). (1 * m) = (m * m)\n",
    "            nabB[-l] = delta + (mo_fac * self.prev_nab_B[-l])  # m * 1\n",
    "        \n",
    "        self.prev_nab_W = nabW\n",
    "        self.prev_nab_B = nabB\n",
    "        \n",
    "        return (nabB, nabW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7706e76-70aa-408c-bd02-75386c1c501a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting SGD with batch size 32, learning rate 0.075\n",
      "up to 50 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-4716345d72a5>:3: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-z))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/50; accuracy: 47.9%.\n",
      "epoch 2/50; accuracy: 49.1%.\n",
      "epoch 3/50; accuracy: 49.0%.\n",
      "epoch 4/50; accuracy: 49.0%.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-dac13de8c404>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mneuNet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNeuralNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m784\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mneuNet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstochasticGradDesc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.075\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestDat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-70173c1ef85e>\u001b[0m in \u001b[0;36mstochasticGradDesc\u001b[0;34m(self, trainDat, nEpoch, sSSize, rate, testDat)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0msubSet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msubSets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdSubSet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubSet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtestDat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-70173c1ef85e>\u001b[0m in \u001b[0;36mupdSubSet\u001b[0;34m(self, subSet, rate)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msubSet\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             \u001b[0mdelNabB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelNabW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpropBwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0mnabB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnB\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdnB\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdnB\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnabB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelNabB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-70173c1ef85e>\u001b[0m in \u001b[0;36mpropBwd\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzVecs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mdelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0ml\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdifsmd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0mnabW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdelta\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0macts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0ml\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmo_fac\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprev_nab_W\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (m * 1). (1 * m) = (m * m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-4716345d72a5>\u001b[0m in \u001b[0;36mdifsmd\u001b[0;34m(z)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdifsmd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msmd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0msmd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0moneHot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-4716345d72a5>\u001b[0m in \u001b[0;36msmd\u001b[0;34m(z)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msmd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;34m\"\"\"sigmoid function\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdifsmd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "neuNet = NeuralNetwork([784, 16, 10, 10])\n",
    "\n",
    "neuNet.stochasticGradDesc(train, 50, 2**5, 0.075, testDat = test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
