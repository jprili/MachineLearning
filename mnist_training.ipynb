{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fc8c50c-b49f-4ee7-8fe4-271da7a18e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from mnist import MNIST\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53f7c6ba-912a-489f-b9ce-b5e9ea853117",
   "metadata": {},
   "outputs": [],
   "source": [
    "mndata = MNIST(\"dat\")\n",
    "train = np.array(mndata.load_training()).T\n",
    "test = np.array(mndata.load_testing()).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a070e63-f1af-4c99-b0e8-6e0872a00cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printShape(name, arr):\n",
    "    print(\"{0} shape:\".format(name) + str(arr.shape))\n",
    "\n",
    "class NeuralNetwork(object):\n",
    "    def __init__(self, sizes):\n",
    "        \"\"\"\n",
    "        constructor for a neural network.\n",
    "        from https://github.com/mnielsen/neural-networks-and-deep-learning/\n",
    "             blob/master/src/network.py\n",
    "        \"\"\"\n",
    "        self.nLayers = len(sizes)\n",
    "        self.sizes = sizes\n",
    "        \n",
    "        # array of bias vectors, list with `nLayers` amount of vecs\n",
    "        # containing `size` elements\n",
    "        \n",
    "        self.biases = [np.random.randn(nextLay, 1) \\\n",
    "                       for nextLay in sizes[1:]]\n",
    "        \n",
    "        # array of weight matrices, if the previous layer is \n",
    "        # sized a, and next layer b, the weight matrix would\n",
    "        # be sized (b * a) to accomodate transformation\n",
    "        # (b * 1) = (b * a) . (a * 1)\n",
    "        \n",
    "        self.weights = [np.random.randn(nextLay, prevLay) \\\n",
    "                        for prevLay, nextLay in zip(sizes[:-1], sizes[1:])]\n",
    "        \n",
    "    def feedFwd(self, arr):\n",
    "        \"\"\"\n",
    "        forward feeding\n",
    "        \"\"\"\n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            arr = self.reLU(np.dot(w, arr) + b)\n",
    "        \n",
    "        return arr\n",
    "    \n",
    "    def stochasticGradDesc(self, trainDat, nEpoch, sSSize, rate, testDat = None):\n",
    "        if testDat is not None: \n",
    "            nTest = len(testDat)\n",
    "        \n",
    "        nTrain = len(trainDat)\n",
    "        \n",
    "        for i in range(nEpoch):\n",
    "            random.shuffle(trainDat)\n",
    "            \n",
    "            subSets = [train[k : k + sSSize] for k in range(0, nTrain, sSSize)]\n",
    "            \n",
    "            for subSet in subSets:\n",
    "                self.updSubSet(subSet, rate)\n",
    "                \n",
    "            if testDat is not None:\n",
    "                print(\"Epoch {0} accuracy: \".format( \\\n",
    "                    i) + str((self.evaluate(testDat)/nTest)*100) + \"%\")\n",
    "                \n",
    "            else:\n",
    "                print(\"Epoch {0} complete\".format(i))\n",
    "        \n",
    "    def updSubSet(self, subSet, rate):\n",
    "        \n",
    "        # initialise weight gradients and bias gradients\n",
    "        \n",
    "        nabB = [np.zeros(b.shape) for b in self.biases]\n",
    "        nabW = [np.zeros(w.shape) for w in self.weights]\n",
    "        \n",
    "        sSSize = len(subSet)\n",
    "        \n",
    "        # update\n",
    "        \n",
    "        for x, y in subSet:\n",
    "            delNabB, delNabW = self.propBwd(x, y)\n",
    "            \n",
    "            nabB = [nB + dnB for nB, dnB in zip(nabB, delNabB)]\n",
    "            nabW = [nW + dnW for nW, dnW in zip(nabW, delNabW)]\n",
    "            \n",
    "            \n",
    "        self.weights = [Wi - ((rate / sSSize) * nabWi) \\\n",
    "                        for Wi, nabWi in zip(self.weights, nabW)]\n",
    "        \n",
    "        self.biases = [Bi - ((rate / sSSize) * nabBi)  \\\n",
    "                       for Bi, nabBi in zip(self.biases, nabB)]\n",
    "        \n",
    "        \n",
    "    def evaluate(self, testDat):\n",
    "        results = [(np.argmax(self.feedFwd(x)), y) for (x, y) in testDat]\n",
    "        # tuple (int, int)\n",
    "        return sum(int(x == y) for (x, y) in results)\n",
    "        \n",
    "        \n",
    "    def difCost(self, outAct, y):\n",
    "        return outAct - y # (10 * 1)\n",
    "        \n",
    "    def propBwd(self, x, y):\n",
    "        \"\"\"\n",
    "        backwards propagation\n",
    "        \n",
    "        x - activation layer: ndarray, size m * 1\n",
    "        y - output: int, could be converted to ndarray, size 10 * 1\n",
    "            with oneHot(y).\n",
    "        \"\"\"\n",
    "        \n",
    "        # initialise weight gradients and bias gradients\n",
    "        \n",
    "        nabB = [np.zeros(b.shape) for b in self.biases]\n",
    "        nabW = [np.zeros(w.shape) for w in self.weights]\n",
    "        \n",
    "        # forward propagation\n",
    "        \n",
    "        act = np.array([x]).T\n",
    "        \n",
    "        acts = [act]\n",
    "        \n",
    "        zVecs = []\n",
    "        \n",
    "        # feedFwd is not called to store the z and a values\n",
    "        \n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            z = np.dot(w, act) + b # (m * 1)\n",
    "            \n",
    "            zVecs.append(z)\n",
    "            \n",
    "            act = self.reLU(z)\n",
    "            acts.append(act)\n",
    "            \n",
    "        # bwd        \n",
    "        delta = self.difCost(acts[-1], self.oneHot(y)) * self.reLU(zVecs[-1])\n",
    "        \n",
    "        nabB[-1] = delta # (out * 1)\n",
    "        nabW[-1] = np.dot(delta, np.array(acts[-2]).T)\n",
    "        \n",
    "        # for the rest of the network\n",
    "        \n",
    "        for l in range(2, self.nLayers):\n",
    "            z = zVecs[-l]\n",
    "            \n",
    "            dReLU = self.difReLU(z)\n",
    "            delta = np.dot(self.weights[-l + 1].T, delta) * dReLU\n",
    "            \n",
    "            nabB[-l] = delta # m * 1\n",
    "            nabW[-l] = np.dot(delta, acts[-l - 1].T) # (m * 1). (1 * m) = (m * m)\n",
    "            \n",
    "        return nabB, nabW\n",
    "    \n",
    "    \n",
    "    ####### activation functions #######\n",
    "            \n",
    "    def smd(self, z):\n",
    "        \"\"\"sigmoid function\"\"\"\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "    \n",
    "    def difsmd(self, z):\n",
    "        return self.smd(z) * (1 - self.smd(z))\n",
    "    \n",
    "    def oneHot(self, y):\n",
    "        arr = np.zeros(10)\n",
    "        arr[y] = 1\n",
    "        return np.array([arr]).T\n",
    "    \n",
    "    def reLU(self, z):\n",
    "        return np.maximum(0, z)\n",
    "    \n",
    "    def difReLU(self, z):\n",
    "        if isinstance(z, np.ndarray):\n",
    "            z = np.array([i > 0 for i in z])\n",
    "            return z\n",
    "        \n",
    "        return z > 0\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fae724ed-018d-4a86-ac5b-0f0d025b1e56",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 accuracy: 9.8%\n",
      "Epoch 1 accuracy: 9.8%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-cf4ed01d16e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mneuNet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNeuralNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m784\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mneuNet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstochasticGradDesc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3001\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestDat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-25b087aee7dd>\u001b[0m in \u001b[0;36mstochasticGradDesc\u001b[0;34m(self, trainDat, nEpoch, sSSize, rate, testDat)\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtestDat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                 print(\"Epoch {0} accuracy: \".format( \\\n\u001b[0;32m---> 53\u001b[0;31m                     i) + str((self.evaluate(testDat)/nTest)*100) + \"%\")\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-25b087aee7dd>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, testDat)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestDat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeedFwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtestDat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m         \u001b[0;31m# tuple (int, int)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-25b087aee7dd>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestDat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeedFwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtestDat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m         \u001b[0;31m# tuple (int, int)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-25b087aee7dd>\u001b[0m in \u001b[0;36mfeedFwd\u001b[0;34m(self, arr)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \"\"\"\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbiases\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "neuNet = NeuralNetwork([784, 16, 10])\n",
    "\n",
    "neuNet.stochasticGradDesc(train[:3001], 20, 5, 0.5, testDat = test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
